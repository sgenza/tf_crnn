import numpy as np
import pandas as pd
from imageio import imread
from scipy.misc import imresize
from utils import label_to_array, to_max_len, sparse_tuple_from
from tensorflow.keras.utils import to_categorical
from mat4py import loadmat
import xmltodict
import random
import config
import tensorflow as tf

def synth_word_generator(path='synth90k', mode='train'):

	'''
	This dataset was generated by M. Jaderberg and others in the paper "Deep Features for Text Spotting"
	
	@InProceedings{Jaderberg14,
      author       = "Jaderberg, M. and Vedaldi, A. and Zisserman, A.",
      title        = "Deep Features for Text Spotting",
      booktitle    = "European Conference on Computer Vision",
      year         = "2014",
    }
    '''

	# File reading
	if mode == 'train':
		file_path = 'annotation_train.txt'
	if mode == 'val':
		file_path = 'annotation_val.txt'
	if mode == 'test':
		file_path = 'annotation_test.txt'

	with open(path + file_path, 'r') as file:
		file_raws = file.readlines()

	dataset_len = len(file_raws)
	print(dataset_len)

	j = 0

	while True:

		# print(j)
		j += 1

		# Random files for this batch
		batch_raws = [random.choice(file_raws) for _ in np.arange(config.batch_size)]

		x_batch = np.empty([config.batch_size, config.img_h, config.img_w, 1])
		y_batch = np.empty(config.batch_size, dtype=np.object)
		dt_batch = np.empty(config.batch_size, dtype=np.object)

		for i, raw in enumerate(batch_raws):

			try:
				img_path = raw.split(' ')[0]
				label = img_path.split('_')[1].upper()
				target = label_to_array(label)
				img = imread(path + img_path)[:, :, 0]

			except (IndexError, SyntaxError, ValueError, OSError):
				print('Error')
				raw = random.choice(file_raws)
				img_path = raw.split(' ')[0]
				label = img_path.split('_')[1].upper()
				target = label_to_array(label)
				img = imread(path + img_path)[:, :, 0]

			img = imresize(img, (config.img_h, config.img_w))[:, :, np.newaxis]

			x_batch[i, :, :, :] = img
			y_batch[i] = label
			dt_batch[i] = target

		x_batch /= 255
		dt_batch = sparse_tuple_from(np.reshape(np.array(dt_batch), (-1)))

		# dt_batch = to_categorical(dt_batch, num_classes=config.num_classes)

		yield x_batch, y_batch, dt_batch

def svt_word_generator(path='SVT/', mode='train'):

	xml_path = 'train.xml' if mode == 'train' else 'test.xml'

	with open(path + xml_path, 'rb') as file:
		
		xmlDict = xmltodict.parse(file)
		df = pd.DataFrame.from_dict(xmlDict)

	x_dataset = []
	y_dataset = []
	tg_dataset = []

	for image in df['tagset']['image']:

		img_path = image['imageName']
		full_img = imread(path + img_path)

		if isinstance(image['taggedRectangles']['taggedRectangle'], list):

			for word in image['taggedRectangles']['taggedRectangle']:

				label = word['tag']
				target = label_to_array(label)

				height = int(word['@height'])
				width = int(word['@width'])
				x = int(word['@x'])
				y = int(word['@y'])

				word = full_img[y:y + height, x:x + width, :]

				if (word.shape[0] == 0) or (word.shape[1] == 0):
					continue

				word = imresize(word, (config.img_h, config.img_w))

				x_dataset.append(word)
				y_dataset.append(label)
				tg_dataset.append(target)

		else:

			word = image['taggedRectangles']['taggedRectangle']
			label = word['tag']
			target = label_to_array(label)

			height = int(word['@height'])
			width = int(word['@width'])
			x = int(word['@x'])
			y = int(word['@y'])

			word = full_img[y:y + height, x:x + width, :]
			word = imresize(word, (config.img_h, config.img_w))

			x_dataset.append(word)
			y_dataset.append(label)
			tg_dataset.append(target)

	x_dataset = np.mean(np.array(x_dataset, dtype=np.float32), axis=-1)[:, :, :, np.newaxis]
	x_dataset /= 255
	y_dataset = np.array(y_dataset, dtype=np.object)
	tg_dataset = np.array(tg_dataset, dtype=np.object)
	print(x_dataset.shape)

	while True:

		idx = np.random.choice(x_dataset.shape[0], config.batch_size)

		# x_batch = np.mean(x_dataset[idx], axis=3)[:, :, :, np.newaxis]
		x_batch = x_dataset[idx]
		y_batch = y_dataset[idx]
		tg_batch = tg_dataset[idx]

		tg_batch = sparse_tuple_from(np.reshape(np.array(tg_batch), (-1)))

		yield x_batch, y_batch, tg_batch

def IIIT5K_word_generator(path='IIIT5K/', mode='train'):

	if mode == 'train':
		file_path = 'traindata.mat'
		key = 'traindata'
	if mode == 'test':
		file_path = 'testdata.mat'
		key = 'testdata'

	x_dataset = []
	y_dataset = []
	tg_dataset = []

	file = loadmat(path + file_path)
	dataset_len = len(file[key]['ImgName'])
	
	for i in np.arange(dataset_len):

		img_path = file[key]['ImgName'][i]
		label = file[key]['GroundTruth'][i]
		target = label_to_array(label)

		img = imread(path + img_path)
		if img.ndim == 2:
			img = np.stack([img, img, img], axis=2)
		img = imresize(img, (config.img_h, config.img_w))

		x_dataset.append(img)
		y_dataset.append(label)
		tg_dataset.append(target)

	x_dataset = np.mean(np.array(x_dataset, dtype=np.float32), axis=-1)[:, :, :, np.newaxis]
	x_dataset /= 255
	y_dataset = np.array(y_dataset, dtype=np.object)
	tg_dataset = np.array(tg_dataset, dtype=np.object)
	print(x_dataset.shape)

	while True:

		idx = np.random.choice(dataset_len, config.batch_size)

		x_batch = x_dataset[idx]
		y_batch = y_dataset[idx]
		tg_batch = tg_dataset[idx]
		tg_batch = sparse_tuple_from(np.reshape(np.array(tg_batch), -1))

		yield x_batch, y_batch, tg_batch

if __name__ == '__main__':

	print('train len')
	data_generator('', 'train').__next__()
	print('val len')
	data_generator('', 'val').__next__()
	print('test len')
	data_generator('', 'test').__next__()
